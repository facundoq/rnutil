{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "AqE_KDgXtGlJ"
   },
   "source": [
    "# Ejercicio 3 -   Regresión Lineal con Keras\n",
    "\n",
    "En este ejercicio, tu objetivo será entrenar modelos de Regresión Lineal utilizando Keras (y Tensorflow como backend) para familiarizarte con la librería y comprender la relación de sus clases y métodos con los que definimos en los ejercicios 1 y 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4OsE2xntGlL"
   },
   "outputs": [],
   "source": [
    "\n",
    "!pip install -q rnutil\n",
    "import rnutil\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3amunskmtGlW"
   },
   "source": [
    "# Creando modelos de regresión y prediciendo valores\n",
    "\n",
    "El siguiente codigo crea modelos de Keras con distintos valores de `w` y `b` y verifica su salida.\n",
    "\n",
    "Para crear un modelo de Keras utilizamos la clase `Sequential`, que permite utilizar modelos de varias capas. No obstante, en este caso vamos a crear modelos con una sola capa, la capa de clase `Dense` (también conocida como `fully connected` o `lineal`), que permite hacer regresión lineal con varias variables de entrada y de salida. \n",
    "\n",
    "Al crear la capa, especificamos la dimensionalidad de salida (1 en este caso) y la de entrada (2 en este caso). De esta forma el modelo puede crear e inicializar los parámetros `W` y `b`.\n",
    "\n",
    "Como estamos probando un modelo puramente lineal, especificamos `activation=None` para que Keras no agregue ninguna función no-lineal a la salida.\n",
    "\n",
    "Por último, utilizamos los parámetros por nombre `kernel_initializer` y `bias_initializer` de la clase `Dense` para especificar como inicializar los parámetros `w` (kernel) y `b` (bias) respectivamente. En este caso, utilizamos `keras.initializers.Constant` para inicializarlo con algunos valores constantes.\n",
    "\n",
    "Ejecuta el siguiente bloque para verificar que en las 4 pruebas la función `predict` de los modelos de Keras hace lo mismo que la función `forward` vista anteriormente. En cada una de las pruebas, estamos inicializando el modelo con distintos valores de `w` y `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ar2beiLutGla"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "x=np.array([[1.0,2.0]\n",
    "            ,[2.0,3.0]\n",
    "            ,[3.0,4.0]])\n",
    "dimensionalidad_salida=1\n",
    "dimensionalidad_entrada=(2,)\n",
    "\n",
    "# PRUEBA 1\n",
    "# Defino un modelo con w=(0,0) y b=0\n",
    "model1 = keras.Sequential([\n",
    "    keras.layers.Dense(dimensionalidad_salida\n",
    "                       # dimensionalidad de la entrada\n",
    "                       ,input_shape=dimensionalidad_entrada\n",
    "                       # activation=None para que no tenga f de activacion (r lineal)\n",
    "                       ,activation=None \n",
    "                       # inicializo w=(0,0)\n",
    "                      , kernel_initializer = keras.initializers.Constant(value=0)\n",
    "                       # inicializo b=0\n",
    "                      , bias_initializer   = keras.initializers.Constant(value=0))\n",
    "])\n",
    "y_prediccion = model1.predict(x)\n",
    "y=np.zeros((3,1))\n",
    "rnutil.verificar_igualdad(y,y_prediccion)\n",
    "\n",
    "  \n",
    "# PRUEBA 2\n",
    "# Defino un modelo con w=(1,1) y b=0\n",
    "model2 = keras.Sequential([\n",
    "    keras.layers.Dense(dimensionalidad_salida\n",
    "                       ,input_shape=dimensionalidad_entrada\n",
    "                       , activation=None\n",
    "                      , kernel_initializer = keras.initializers.Constant(value=1)\n",
    "                      , bias_initializer   = keras.initializers.Constant(value=0))\n",
    "])\n",
    "\n",
    "y_prediccion = model2.predict(x)\n",
    "y=np.array([[3.0,5.0,7.0]]).T\n",
    "rnutil.verificar_igualdad(y,y_prediccion)\n",
    "\n",
    "# PRUEBA 3\n",
    "# Defino un modelo con w=(0,0) y b=1\n",
    "model3 = keras.Sequential([\n",
    "    keras.layers.Dense(dimensionalidad_salida\n",
    "                       ,input_shape=dimensionalidad_entrada\n",
    "                       , activation=None\n",
    "                      , kernel_initializer = keras.initializers.Constant(value=0)\n",
    "                      , bias_initializer   = keras.initializers.Constant(value=1))\n",
    "])\n",
    "y=np.ones((3,1))\n",
    "y_prediccion = model3.predict(x)\n",
    "rnutil.verificar_igualdad(y,y_prediccion)\n",
    "\n",
    "# PRUEBA 4\n",
    "# Defino un modelo con w=(1,1) y b=1\n",
    "model4 = keras.Sequential([\n",
    "    keras.layers.Dense(dimensionalidad_salida\n",
    "                       ,input_shape=dimensionalidad_entrada\n",
    "                       , activation=None\n",
    "                      , kernel_initializer = keras.initializers.Constant(value=1)\n",
    "                      , bias_initializer   = keras.initializers.Constant(value=1))\n",
    "])\n",
    "y_prediccion = model4.predict(x)\n",
    "y=np.array([[4.0,6.0,8.0]]).T\n",
    "rnutil.verificar_igualdad(y,y_prediccion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JWc6FRjtGli"
   },
   "source": [
    "# Entrenar un modelo de Regresión Lineal con Keras para el dataset de estudio 2D\n",
    "\n",
    "El siguiente código carga un dataset de prueba con 2 dimensiones de entrada y una de salida.\n",
    "\n",
    "Luego crea un modelo de regresión lineal con Keras, y visualiza sus pesos iniciales. \n",
    "\n",
    "Es importante notar tres cosas:\n",
    "\n",
    "1. La métrica utilizada es `'mse'`, es decir el error cuadrático medio o promedio. Esta es la misma métrica vista en la teoría de Regresión Lineal.\n",
    "\n",
    "2. El optimizador es una clase que define el algoritmo para minimizar el error cuadrático. En general, son todas variantes de descenso de gradiente. En este caso, estamos utilizando descenso de gradiente estocástico (`keras.optimizers.SGD`), que es igual al descenso de gradiente pero realiza cada actualización de los parámetros con un subconjunto de los ejemplos del dataset. \n",
    "\n",
    "3. El método para entrenar el modelo es `fit`. En este caso, el parámetro `lr` lo recibe el optimizador, pero `fit` recibe la cantidad de iteraciones (`epochs`) y el tamaño del batch para el SGD (`batch_size`).\n",
    "\n",
    "\n",
    "Al finalizar el entrenamiento, observá los valores del vector de pesos `w`. ¿A qué atributo o variable de entrada le da más importancia el modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q-jpUmyxtGll"
   },
   "outputs": [],
   "source": [
    "# Carga del dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = rnutil.load_dataset_numpy(\"study_regression_2d_small.csv\")\n",
    "\n",
    "x,y=data[:,0:2],data[:,2:3]\n",
    "n,d_in=x.shape\n",
    "n,d_out=y.shape\n",
    "\n",
    "# Creación del modelo inicial\n",
    "print(\"Inicialización aleatoria del modelo; vuelve a correr esta celda para obtener otros resultados\")\n",
    "# Creo un modelo lineal\n",
    "modelo = keras.Sequential([\n",
    "    keras.layers.Dense(d_out,input_shape=(d_in,), activation=None)])\n",
    "\n",
    "# visualización del modelo inicial\n",
    "mensaje=f\"Modelo inicial\"\n",
    "w,b=modelo.get_weights()\n",
    "\n",
    "rnutil.plot_regresion_lineal(w,b,x[:,0],x[:,1],y,x1_label=\"Horas\",x2_label=\"Promedio\",y_label=\"Nota\",title=mensaje)\n",
    "\n",
    "\n",
    "#Creo el optimizador y compilo el modelo para usarlo\n",
    "α=0.001\n",
    "# Algoritmo de optimización: Descenso de Gradiente Estocástico (Stochastic Gradient Descent)\n",
    "sgd = keras.optimizers.SGD(learning_rate=α)\n",
    "# error cuadrático medio es la métrica de error a optimizar\n",
    "error_metric='mse' # IMPORTANTE\n",
    "\n",
    "modelo.compile(\n",
    "  optimizer=sgd,\n",
    "  loss=error_metric,\n",
    "  metrics=['mae'], # metricas para ir calculando en cada iteracion o batch (ninguna ahora)\n",
    ")\n",
    "\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "history  = modelo.fit(x,y,epochs=15,batch_size=32)\n",
    "\n",
    "# dibujar curva de error\n",
    "rnutil.plot_loss(history.history[\"loss\"])\n",
    "\n",
    "\n",
    "# visualiza el modelo y los datos\n",
    "w,b=modelo.get_weights()\n",
    "\n",
    "rnutil.plot_regresion_lineal(w,b,x[:,0],x[:,1],y,x1_label=\"Horas\",x2_label=\"Promedio\",y_label=\"Nota\",title=\"Modelo Final\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Regresion Lineal con Keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
